name: CD

on:
  push:
    branches: [ "**" ]
    tags: [ 'v*' ]

env:
  REGISTRY: ghcr.io
  FRONTEND_IMAGE: ghcr.io/${{ github.repository_owner }}/scalable-microservices-dashboard-with-ai/frontend
  API_GATEWAY_IMAGE: ghcr.io/${{ github.repository_owner }}/scalable-microservices-dashboard-with-ai/api-gateway
  AI_SERVICE_IMAGE: ghcr.io/${{ github.repository_owner }}/scalable-microservices-dashboard-with-ai/ai-service
  WORKER_SERVICE_IMAGE: ghcr.io/${{ github.repository_owner }}/scalable-microservices-dashboard-with-ai/worker-service

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            ${{ env.FRONTEND_IMAGE }}
            ${{ env.API_GATEWAY_IMAGE }}
            ${{ env.AI_SERVICE_IMAGE }}
            ${{ env.WORKER_SERVICE_IMAGE }}
          tags: |
            type=semver,pattern={{version}}
            type=sha,format=long
            type=ref,event=branch

      - name: Build and push Frontend
        uses: docker/build-push-action@v5
        with:
          context: .
          file: frontend/Dockerfile.dev
          push: true
          tags: ${{ env.FRONTEND_IMAGE }}:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.FRONTEND_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ env.FRONTEND_IMAGE }}:buildcache,mode=max

      - name: Build and push API Gateway
        uses: docker/build-push-action@v5
        with:
          context: .
          file: backend/api-gateway/Dockerfile.dev
          push: true
          tags: ${{ env.API_GATEWAY_IMAGE }}:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.API_GATEWAY_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ env.API_GATEWAY_IMAGE }}:buildcache,mode=max

      - name: Build and push AI Service
        uses: docker/build-push-action@v5
        with:
          context: .
          file: backend/ai-service/Dockerfile.dev
          push: true
          tags: ${{ env.AI_SERVICE_IMAGE }}:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.AI_SERVICE_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ env.AI_SERVICE_IMAGE }}:buildcache,mode=max

      - name: Build and push Worker Service
        uses: docker/build-push-action@v5
        with:
          context: .
          file: backend/worker-service/Dockerfile.dev
          push: true
          tags: ${{ env.WORKER_SERVICE_IMAGE }}:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=registry,ref=${{ env.WORKER_SERVICE_IMAGE }}:buildcache
          cache-to: type=registry,ref=${{ env.WORKER_SERVICE_IMAGE }}:buildcache,mode=max

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master' || startsWith(github.ref, 'refs/tags/v')

    steps:
      - uses: actions/checkout@v4

      - name: Create k8s Kind Cluster
        uses: helm/kind-action@v1.8.0

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'

      - name: Load images into kind cluster
        run: |
          # Pull the images that were just pushed
          VERSION=${{ needs.build-and-push.outputs.version || 'latest' }}
          FRONTEND_IMAGE_TAG="${{ env.FRONTEND_IMAGE }}:${VERSION}"
          API_GATEWAY_IMAGE_TAG="${{ env.API_GATEWAY_IMAGE }}:${VERSION}"
          AI_SERVICE_IMAGE_TAG="${{ env.AI_SERVICE_IMAGE }}:${VERSION}"
          WORKER_SERVICE_IMAGE_TAG="${{ env.WORKER_SERVICE_IMAGE }}:${VERSION}"

          echo "üîΩ Pulling images from GHCR..."
          docker pull ${FRONTEND_IMAGE_TAG} || echo "‚ö†Ô∏è Failed to pull frontend"
          docker pull ${API_GATEWAY_IMAGE_TAG} || echo "‚ö†Ô∏è Failed to pull api-gateway"
          docker pull ${AI_SERVICE_IMAGE_TAG} || echo "‚ö†Ô∏è Failed to pull ai-service"
          docker pull ${WORKER_SERVICE_IMAGE_TAG} || echo "‚ö†Ô∏è Failed to pull worker-service"

          echo "üì¶ Loading images into kind cluster..."
          kind load docker-image ${FRONTEND_IMAGE_TAG} --name chart-testing || echo "‚ö†Ô∏è Failed to load frontend"
          kind load docker-image ${API_GATEWAY_IMAGE_TAG} --name chart-testing || echo "‚ö†Ô∏è Failed to load api-gateway"
          kind load docker-image ${AI_SERVICE_IMAGE_TAG} --name chart-testing || echo "‚ö†Ô∏è Failed to load ai-service"
          kind load docker-image ${WORKER_SERVICE_IMAGE_TAG} --name chart-testing || echo "‚ö†Ô∏è Failed to load worker-service"

      - name: Deploy to local Kubernetes
        run: |
          # Create namespace
          kubectl create namespace dashboard-app || true

          # Update image tags in Kubernetes manifests
          VERSION=${{ needs.build-and-push.outputs.version || 'latest' }}
          FRONTEND_IMAGE_TAG="${{ env.FRONTEND_IMAGE }}:${VERSION}"
          API_GATEWAY_IMAGE_TAG="${{ env.API_GATEWAY_IMAGE }}:${VERSION}"
          AI_SERVICE_IMAGE_TAG="${{ env.AI_SERVICE_IMAGE }}:${VERSION}"
          WORKER_SERVICE_IMAGE_TAG="${{ env.WORKER_SERVICE_IMAGE }}:${VERSION}"

          # Quote image values to avoid YAML parse issues
          sed -i -E "s|^(\s*image:)\s*.*$|\1 \"${FRONTEND_IMAGE_TAG}\"|" k8s/frontend.yaml
          sed -i -E "s|^(\s*image:)\s*.*$|\1 \"${API_GATEWAY_IMAGE_TAG}\"|" k8s/api-gateway.yaml
          sed -i -E "s|^(\s*image:)\s*.*$|\1 \"${AI_SERVICE_IMAGE_TAG}\"|" k8s/ai-service.yaml
          sed -i -E "s|^(\s*image:)\s*.*$|\1 \"${WORKER_SERVICE_IMAGE_TAG}\"|" k8s/worker-service.yaml
          
          # Apply Kubernetes manifests
          kubectl apply -f k8s/ -n dashboard-app

      - name: Check deployment status and debug failures
        run: |
          echo "üìä Current deployment status:"
          kubectl get all -n dashboard-app
          
          echo "üîç Checking pod status:"
          kubectl get pods -n dashboard-app -o wide
          
          echo "üîé Describing deployments:"
          kubectl describe deployments -n dashboard-app
          
          echo "üìã Pod events and logs for debugging:"
          for pod in $(kubectl get pods -n dashboard-app -o name); do
            echo "=== Describing $pod ==="
            kubectl describe $pod -n dashboard-app || true
            echo "=== Logs for $pod ==="
            kubectl logs $pod -n dashboard-app --tail=50 || true
          done

      - name: Wait for deployments
        run: |
          kubectl wait --for=condition=available --timeout=300s deployment/frontend -n dashboard-app || {
            echo "‚ùå Frontend deployment failed to become available"
            kubectl describe deployment/frontend -n dashboard-app
            kubectl logs -l app=frontend -n dashboard-app --tail=100
            exit 1
          }
          kubectl wait --for=condition=available --timeout=300s deployment/api-gateway -n dashboard-app || {
            echo "‚ùå API Gateway deployment failed to become available"
            kubectl describe deployment/api-gateway -n dashboard-app
            kubectl logs -l app=api-gateway -n dashboard-app --tail=100
            exit 1
          }
          kubectl wait --for=condition=available --timeout=300s deployment/ai-service -n dashboard-app || {
            echo "‚ùå AI Service deployment failed to become available"
            kubectl describe deployment/ai-service -n dashboard-app
            kubectl logs -l app=ai-service -n dashboard-app --tail=100
            exit 1
          }
          kubectl wait --for=condition=available --timeout=300s deployment/worker-service -n dashboard-app || {
            echo "‚ùå Worker Service deployment failed to become available"
            kubectl describe deployment/worker-service -n dashboard-app
            kubectl logs -l app=worker-service -n dashboard-app --tail=100
            exit 1
          }

      - name: Test deployment
        run: |
          kubectl get all -n dashboard-app
          echo "‚úÖ All deployments are healthy"